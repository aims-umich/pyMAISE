{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5519d711-f26c-4d74-a03d-3372e4cf2e00",
   "metadata": {},
   "source": [
    "# H2O Benchmark: HTGR Micro-Core Quadrant Power\n",
    "\n",
    "**Input**\n",
    "\n",
    "- `theta1`: Angle of control drum in quadrant 1 (radians) \n",
    "- `theta2`: Angle of control drum in quadrant 1 (radians) \n",
    "- `theta3`: Angle of control drum in quadrant 2 (radians)  \n",
    "- `theta4`: Angle of control drum in quadrant 2 (radians)\n",
    "- `theta5`: Angle of control drum in quadrant 3 (radians)\n",
    "- `theta6`: Angle of control drum in quadrant 3 (radians)\n",
    "- `theta7`: Angle of control drum in quadrant 4 (radians)  \n",
    "- `theta8`: Angle of control drum in quadrant 4 (radians)  \n",
    "\n",
    "**Output** \n",
    "\n",
    "- `fluxQ1` : Neutron flux in quadrant 1 ($\\frac{neutrons}{cm^{2} s}$)\n",
    "- `fluxQ2` : Neutron flux in quadrant 2 ($\\frac{neutrons}{cm^{2} s}$)\n",
    "- `fluxQ3` : Neutron flux in quadrant 3 ($\\frac{neutrons}{cm^{2} s}$)\n",
    "- `fluxQ4` : Neutron flux in quadrant 4 ($\\frac{neutrons}{cm^{2} s}$)\n",
    "\n",
    "\n",
    "We will be benchmarking the complete HTGR dataset of 3004 samples using H2O ML (version 3.46.0.5) in efforts to compare pyMAISE to other industry standard ML benchmarking frameworks. We will be following the same procedures we did in the original HTGR example, first extending the dataset to 3004 samples using symmetry, and then training and evaluating to compare results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b0c9d0-c21e-4bb8-9018-17b56a1e0ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set display option to show all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Set the width of the columns\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# See the full content of each column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "# Plot settings\n",
    "matplotlib_settings = {\n",
    "    \"font.size\": 12,\n",
    "    \"legend.fontsize\": 11,\n",
    "    \"figure.figsize\": (8, 8)\n",
    "}\n",
    "plt.rcParams.update(**matplotlib_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762b042e-77f9-4b93-a846-5cfcec082d0b",
   "metadata": {},
   "source": [
    "## Processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa66a223-826f-4ccf-bc72-424e97a8fdfd",
   "metadata": {},
   "source": [
    "First, we will load the raw data into a dataframe and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1545ffc-bce4-4638-91df-448454c91cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample number</th>\n",
       "      <th>cpu_time</th>\n",
       "      <th>runtime</th>\n",
       "      <th>k</th>\n",
       "      <th>fluxQ1</th>\n",
       "      <th>fluxQ2</th>\n",
       "      <th>fluxQ3</th>\n",
       "      <th>fluxQ4</th>\n",
       "      <th>k_uncert</th>\n",
       "      <th>flux_runcertQ1</th>\n",
       "      <th>flux_runcertQ2</th>\n",
       "      <th>flux_runcertQ3</th>\n",
       "      <th>flux_runcertQ4</th>\n",
       "      <th>fissQ1</th>\n",
       "      <th>fissQ2</th>\n",
       "      <th>fissQ3</th>\n",
       "      <th>fissQ4</th>\n",
       "      <th>fissEQ1</th>\n",
       "      <th>fissEQ2</th>\n",
       "      <th>fissEQ3</th>\n",
       "      <th>fissEQ4</th>\n",
       "      <th>fiss_runcertQ1</th>\n",
       "      <th>fiss_runcertQ2</th>\n",
       "      <th>fiss_runcertQ3</th>\n",
       "      <th>fiss_runcertQ4</th>\n",
       "      <th>fissE_runcertQ1</th>\n",
       "      <th>fissE_runcertQ2</th>\n",
       "      <th>fissE_runcertQ3</th>\n",
       "      <th>fissE_runcertQ4</th>\n",
       "      <th>theta1</th>\n",
       "      <th>theta2</th>\n",
       "      <th>theta3</th>\n",
       "      <th>theta4</th>\n",
       "      <th>theta5</th>\n",
       "      <th>theta6</th>\n",
       "      <th>theta7</th>\n",
       "      <th>theta8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_00000</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.998328</td>\n",
       "      <td>2.580000e+19</td>\n",
       "      <td>2.590000e+19</td>\n",
       "      <td>2.670000e+19</td>\n",
       "      <td>2.560000e+19</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>0.00112</td>\n",
       "      <td>0.00111</td>\n",
       "      <td>0.00111</td>\n",
       "      <td>0.00108</td>\n",
       "      <td>8.490000e+16</td>\n",
       "      <td>8.490000e+16</td>\n",
       "      <td>8.480000e+16</td>\n",
       "      <td>8.490000e+16</td>\n",
       "      <td>2751290</td>\n",
       "      <td>2751060</td>\n",
       "      <td>2749270</td>\n",
       "      <td>2750450</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00062</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.00062</td>\n",
       "      <td>5.919526</td>\n",
       "      <td>2.369503</td>\n",
       "      <td>2.923656</td>\n",
       "      <td>4.488987</td>\n",
       "      <td>3.683212</td>\n",
       "      <td>4.008905</td>\n",
       "      <td>4.970368</td>\n",
       "      <td>2.987966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_00001</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.988522</td>\n",
       "      <td>2.550000e+19</td>\n",
       "      <td>2.530000e+19</td>\n",
       "      <td>2.510000e+19</td>\n",
       "      <td>2.510000e+19</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.00142</td>\n",
       "      <td>0.00148</td>\n",
       "      <td>0.00154</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>8.490000e+16</td>\n",
       "      <td>8.490000e+16</td>\n",
       "      <td>8.490000e+16</td>\n",
       "      <td>8.490000e+16</td>\n",
       "      <td>2750610</td>\n",
       "      <td>2750210</td>\n",
       "      <td>2750150</td>\n",
       "      <td>2750110</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.00084</td>\n",
       "      <td>0.00074</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.00084</td>\n",
       "      <td>0.00074</td>\n",
       "      <td>2.162380</td>\n",
       "      <td>0.273624</td>\n",
       "      <td>0.927741</td>\n",
       "      <td>4.595586</td>\n",
       "      <td>2.598824</td>\n",
       "      <td>0.170167</td>\n",
       "      <td>2.124048</td>\n",
       "      <td>4.980209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_00002</td>\n",
       "      <td>2590.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.004610</td>\n",
       "      <td>2.570000e+19</td>\n",
       "      <td>2.580000e+19</td>\n",
       "      <td>2.520000e+19</td>\n",
       "      <td>2.520000e+19</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.00167</td>\n",
       "      <td>0.00163</td>\n",
       "      <td>0.00161</td>\n",
       "      <td>0.00165</td>\n",
       "      <td>8.480000e+16</td>\n",
       "      <td>8.480000e+16</td>\n",
       "      <td>8.490000e+16</td>\n",
       "      <td>8.490000e+16</td>\n",
       "      <td>2748870</td>\n",
       "      <td>2749690</td>\n",
       "      <td>2752250</td>\n",
       "      <td>2751840</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.00086</td>\n",
       "      <td>0.00080</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.00086</td>\n",
       "      <td>0.00080</td>\n",
       "      <td>0.450100</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>2.512217</td>\n",
       "      <td>3.313864</td>\n",
       "      <td>1.913458</td>\n",
       "      <td>3.582252</td>\n",
       "      <td>0.280764</td>\n",
       "      <td>4.888595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_00003</td>\n",
       "      <td>2580.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>2.570000e+19</td>\n",
       "      <td>2.580000e+19</td>\n",
       "      <td>2.520000e+19</td>\n",
       "      <td>2.560000e+19</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.00193</td>\n",
       "      <td>0.00195</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>8.480000e+16</td>\n",
       "      <td>8.490000e+16</td>\n",
       "      <td>8.480000e+16</td>\n",
       "      <td>8.470000e+16</td>\n",
       "      <td>2748920</td>\n",
       "      <td>2750720</td>\n",
       "      <td>2749330</td>\n",
       "      <td>2746220</td>\n",
       "      <td>0.00082</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.00080</td>\n",
       "      <td>0.00078</td>\n",
       "      <td>0.00082</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.00080</td>\n",
       "      <td>0.00078</td>\n",
       "      <td>0.461105</td>\n",
       "      <td>4.825628</td>\n",
       "      <td>3.771356</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>2.056019</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>1.106786</td>\n",
       "      <td>5.504671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_00004</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.985047</td>\n",
       "      <td>2.540000e+19</td>\n",
       "      <td>2.620000e+19</td>\n",
       "      <td>2.580000e+19</td>\n",
       "      <td>2.520000e+19</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.00167</td>\n",
       "      <td>0.00167</td>\n",
       "      <td>0.00172</td>\n",
       "      <td>0.00169</td>\n",
       "      <td>8.480000e+16</td>\n",
       "      <td>8.490000e+16</td>\n",
       "      <td>8.480000e+16</td>\n",
       "      <td>8.490000e+16</td>\n",
       "      <td>2748910</td>\n",
       "      <td>2753130</td>\n",
       "      <td>2747870</td>\n",
       "      <td>2752420</td>\n",
       "      <td>0.00080</td>\n",
       "      <td>0.00081</td>\n",
       "      <td>0.00082</td>\n",
       "      <td>0.00083</td>\n",
       "      <td>0.00080</td>\n",
       "      <td>0.00081</td>\n",
       "      <td>0.00082</td>\n",
       "      <td>0.00083</td>\n",
       "      <td>5.248202</td>\n",
       "      <td>3.549416</td>\n",
       "      <td>3.333632</td>\n",
       "      <td>3.907310</td>\n",
       "      <td>2.095312</td>\n",
       "      <td>5.585145</td>\n",
       "      <td>3.774253</td>\n",
       "      <td>2.480120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample number  cpu_time  runtime         k        fluxQ1        fluxQ2  \\\n",
       "0  sample_00000    4260.0    200.0  0.998328  2.580000e+19  2.590000e+19   \n",
       "1  sample_00001    2570.0    130.0  0.988522  2.550000e+19  2.530000e+19   \n",
       "2  sample_00002    2590.0    130.0  1.004610  2.570000e+19  2.580000e+19   \n",
       "3  sample_00003    2580.0    129.0  0.991892  2.570000e+19  2.580000e+19   \n",
       "4  sample_00004    2570.0    129.0  0.985047  2.540000e+19  2.620000e+19   \n",
       "\n",
       "         fluxQ3        fluxQ4  k_uncert  flux_runcertQ1  flux_runcertQ2  \\\n",
       "0  2.670000e+19  2.560000e+19   0.00019         0.00112         0.00111   \n",
       "1  2.510000e+19  2.510000e+19   0.00025         0.00142         0.00148   \n",
       "2  2.520000e+19  2.520000e+19   0.00025         0.00167         0.00163   \n",
       "3  2.520000e+19  2.560000e+19   0.00025         0.00197         0.00193   \n",
       "4  2.580000e+19  2.520000e+19   0.00025         0.00167         0.00167   \n",
       "\n",
       "   flux_runcertQ3  flux_runcertQ4        fissQ1        fissQ2        fissQ3  \\\n",
       "0         0.00111         0.00108  8.490000e+16  8.490000e+16  8.480000e+16   \n",
       "1         0.00154         0.00150  8.490000e+16  8.490000e+16  8.490000e+16   \n",
       "2         0.00161         0.00165  8.480000e+16  8.480000e+16  8.490000e+16   \n",
       "3         0.00195         0.00200  8.480000e+16  8.490000e+16  8.480000e+16   \n",
       "4         0.00172         0.00169  8.480000e+16  8.490000e+16  8.480000e+16   \n",
       "\n",
       "         fissQ4  fissEQ1  fissEQ2  fissEQ3  fissEQ4  fiss_runcertQ1  \\\n",
       "0  8.490000e+16  2751290  2751060  2749270  2750450         0.00060   \n",
       "1  8.490000e+16  2750610  2750210  2750150  2750110         0.00076   \n",
       "2  8.490000e+16  2748870  2749690  2752250  2751840         0.00076   \n",
       "3  8.470000e+16  2748920  2750720  2749330  2746220         0.00082   \n",
       "4  8.490000e+16  2748910  2753130  2747870  2752420         0.00080   \n",
       "\n",
       "   fiss_runcertQ2  fiss_runcertQ3  fiss_runcertQ4  fissE_runcertQ1  \\\n",
       "0         0.00060         0.00063         0.00062          0.00060   \n",
       "1         0.00077         0.00084         0.00074          0.00076   \n",
       "2         0.00077         0.00086         0.00080          0.00076   \n",
       "3         0.00076         0.00080         0.00078          0.00082   \n",
       "4         0.00081         0.00082         0.00083          0.00080   \n",
       "\n",
       "   fissE_runcertQ2  fissE_runcertQ3  fissE_runcertQ4    theta1    theta2  \\\n",
       "0          0.00060          0.00063          0.00062  5.919526  2.369503   \n",
       "1          0.00077          0.00084          0.00074  2.162380  0.273624   \n",
       "2          0.00077          0.00086          0.00080  0.450100  0.006301   \n",
       "3          0.00076          0.00080          0.00078  0.461105  4.825628   \n",
       "4          0.00081          0.00082          0.00083  5.248202  3.549416   \n",
       "\n",
       "     theta3    theta4    theta5    theta6    theta7    theta8  \n",
       "0  2.923656  4.488987  3.683212  4.008905  4.970368  2.987966  \n",
       "1  0.927741  4.595586  2.598824  0.170167  2.124048  4.980209  \n",
       "2  2.512217  3.313864  1.913458  3.582252  0.280764  4.888595  \n",
       "3  3.771356  2.599278  2.056019  0.007332  1.106786  5.504671  \n",
       "4  3.333632  3.907310  2.095312  5.585145  3.774253  2.480120  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "new_cwd = cwd.replace(\"/docs/source/benchmarks\", \"/pyMAISE/datasets\")\n",
    "\n",
    "# Define the full path to the microreactor.csv file\n",
    "csv_path = os.path.join(new_cwd, 'microreactor.csv')\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "raw_data = pd.read_csv(csv_path)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31d3b9-d7a4-4ad4-95d1-f0e258b5cddf",
   "metadata": {},
   "source": [
    "We are then going to create input and output dataframes by defining our input and output variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e40bda25-dcf9-4604-a3eb-ccd069ba8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the input DataFrame with theta values\n",
    "input_columns = ['theta1', 'theta2', 'theta3', 'theta4', 'theta5', 'theta6', 'theta7', 'theta8']\n",
    "inputs = raw_data[input_columns]\n",
    "\n",
    "# Create the output DataFrame with flux values\n",
    "output_columns = ['fluxQ1', 'fluxQ2', 'fluxQ3', 'fluxQ4']\n",
    "outputs = raw_data[output_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d688ceeb-e9fc-4f1c-af4c-b8364f2ec17e",
   "metadata": {},
   "source": [
    "Below, we print out the results for input and output then also create a combined dataset with both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87def8e9-4377-4467-a39b-53dc1bbc4089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta1</th>\n",
       "      <th>theta2</th>\n",
       "      <th>theta3</th>\n",
       "      <th>theta4</th>\n",
       "      <th>theta5</th>\n",
       "      <th>theta6</th>\n",
       "      <th>theta7</th>\n",
       "      <th>theta8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.919526</td>\n",
       "      <td>2.369503</td>\n",
       "      <td>2.923656</td>\n",
       "      <td>4.488987</td>\n",
       "      <td>3.683212</td>\n",
       "      <td>4.008905</td>\n",
       "      <td>4.970368</td>\n",
       "      <td>2.987966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.162380</td>\n",
       "      <td>0.273624</td>\n",
       "      <td>0.927741</td>\n",
       "      <td>4.595586</td>\n",
       "      <td>2.598824</td>\n",
       "      <td>0.170167</td>\n",
       "      <td>2.124048</td>\n",
       "      <td>4.980209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.450100</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>2.512217</td>\n",
       "      <td>3.313864</td>\n",
       "      <td>1.913458</td>\n",
       "      <td>3.582252</td>\n",
       "      <td>0.280764</td>\n",
       "      <td>4.888595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.461105</td>\n",
       "      <td>4.825628</td>\n",
       "      <td>3.771356</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>2.056019</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>1.106786</td>\n",
       "      <td>5.504671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.248202</td>\n",
       "      <td>3.549416</td>\n",
       "      <td>3.333632</td>\n",
       "      <td>3.907310</td>\n",
       "      <td>2.095312</td>\n",
       "      <td>5.585145</td>\n",
       "      <td>3.774253</td>\n",
       "      <td>2.480120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     theta1    theta2    theta3    theta4    theta5    theta6    theta7  \\\n",
       "0  5.919526  2.369503  2.923656  4.488987  3.683212  4.008905  4.970368   \n",
       "1  2.162380  0.273624  0.927741  4.595586  2.598824  0.170167  2.124048   \n",
       "2  0.450100  0.006301  2.512217  3.313864  1.913458  3.582252  0.280764   \n",
       "3  0.461105  4.825628  3.771356  2.599278  2.056019  0.007332  1.106786   \n",
       "4  5.248202  3.549416  3.333632  3.907310  2.095312  5.585145  3.774253   \n",
       "\n",
       "     theta8  \n",
       "0  2.987966  \n",
       "1  4.980209  \n",
       "2  4.888595  \n",
       "3  5.504671  \n",
       "4  2.480120  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293ab317-d7e1-4fcf-aa94-5e3758e5a22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fluxQ1</th>\n",
       "      <th>fluxQ2</th>\n",
       "      <th>fluxQ3</th>\n",
       "      <th>fluxQ4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.580000e+19</td>\n",
       "      <td>2.590000e+19</td>\n",
       "      <td>2.670000e+19</td>\n",
       "      <td>2.560000e+19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.550000e+19</td>\n",
       "      <td>2.530000e+19</td>\n",
       "      <td>2.510000e+19</td>\n",
       "      <td>2.510000e+19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.570000e+19</td>\n",
       "      <td>2.580000e+19</td>\n",
       "      <td>2.520000e+19</td>\n",
       "      <td>2.520000e+19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.570000e+19</td>\n",
       "      <td>2.580000e+19</td>\n",
       "      <td>2.520000e+19</td>\n",
       "      <td>2.560000e+19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.540000e+19</td>\n",
       "      <td>2.620000e+19</td>\n",
       "      <td>2.580000e+19</td>\n",
       "      <td>2.520000e+19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fluxQ1        fluxQ2        fluxQ3        fluxQ4\n",
       "0  2.580000e+19  2.590000e+19  2.670000e+19  2.560000e+19\n",
       "1  2.550000e+19  2.530000e+19  2.510000e+19  2.510000e+19\n",
       "2  2.570000e+19  2.580000e+19  2.520000e+19  2.520000e+19\n",
       "3  2.570000e+19  2.580000e+19  2.520000e+19  2.560000e+19\n",
       "4  2.540000e+19  2.620000e+19  2.580000e+19  2.520000e+19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dfa175a-b363-4c23-ba85-d80d515128a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     theta1    theta2    theta3    theta4    theta5    theta6    theta7  \\\n",
      "0  5.919526  2.369503  2.923656  4.488987  3.683212  4.008905  4.970368   \n",
      "1  2.162380  0.273624  0.927741  4.595586  2.598824  0.170167  2.124048   \n",
      "2  0.450100  0.006301  2.512217  3.313864  1.913458  3.582252  0.280764   \n",
      "3  0.461105  4.825628  3.771356  2.599278  2.056019  0.007332  1.106786   \n",
      "4  5.248202  3.549416  3.333632  3.907310  2.095312  5.585145  3.774253   \n",
      "\n",
      "     theta8        fluxQ1        fluxQ2        fluxQ3        fluxQ4  \n",
      "0  2.987966  2.580000e+19  2.590000e+19  2.670000e+19  2.560000e+19  \n",
      "1  4.980209  2.550000e+19  2.530000e+19  2.510000e+19  2.510000e+19  \n",
      "2  4.888595  2.570000e+19  2.580000e+19  2.520000e+19  2.520000e+19  \n",
      "3  5.504671  2.570000e+19  2.580000e+19  2.520000e+19  2.560000e+19  \n",
      "4  2.480120  2.540000e+19  2.620000e+19  2.580000e+19  2.520000e+19  \n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([inputs, outputs], axis=1)\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532d981-6683-42b2-87d5-fc4a18e9b613",
   "metadata": {},
   "source": [
    "Now it is time to extend the dataset to 3004 samples. This is done in the same way as in the original HTGR, replicating the same steps below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee65be9b-4c39-4e8f-8952-5f4e8b7bb814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit to mult_sym and g21 from https://github.com/deanrp2/MicroControl/blob/main/pmdata/utils.py#L51\n",
    "theta_cols = [f\"theta{i + 1}\" for i in range(8)]\n",
    "flux_cols = [f\"fluxQ{i + 1}\" for i in range(4)]\n",
    "\n",
    "def mult_samples(data):\n",
    "    # Create empty arrays\n",
    "    ht = xr.DataArray(\n",
    "        np.zeros(data.shape), \n",
    "        coords={\n",
    "            \"index\": [f\"{idx}_h\" for idx in data.coords[\"index\"].values],\n",
    "            \"variable\": data.coords[\"variable\"],\n",
    "        },\n",
    "    )\n",
    "    vt = xr.DataArray(\n",
    "        np.zeros(data.shape), \n",
    "        coords={\n",
    "            \"index\": [f\"{idx}_v\" for idx in data.coords[\"index\"].values],\n",
    "            \"variable\": data.coords[\"variable\"],\n",
    "        },\n",
    "    )\n",
    "    rt = xr.DataArray(\n",
    "        np.zeros(data.shape),     \n",
    "        coords={\n",
    "            \"index\": [f\"{idx}_r\" for idx in data.coords[\"index\"].values],\n",
    "            \"variable\": data.coords[\"variable\"],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Swap drum positions\n",
    "    hkey = [f\"theta{i}\" for i in np.array([3, 2, 1, 0, 7, 6, 5, 4], dtype=int) + 1]\n",
    "    vkey = [f\"theta{i}\" for i in np.array([7, 6, 5, 4, 3, 2, 1, 0], dtype=int) + 1]\n",
    "    rkey = [f\"theta{i}\" for i in np.array([4, 5, 6, 7, 0, 1, 2, 3], dtype=int) + 1]\n",
    "\n",
    "    ht.loc[:, hkey] = data.loc[:, theta_cols].values\n",
    "    vt.loc[:, vkey] = data.loc[:, theta_cols].values\n",
    "    rt.loc[:, rkey] = data.loc[:, theta_cols].values\n",
    "\n",
    "    # Adjust angles\n",
    "    ht.loc[:, hkey] = (3 * np.pi - ht.loc[:, hkey].loc[:, hkey]) % (2 * np.pi)\n",
    "    vt.loc[:, vkey] = (2 * np.pi - vt.loc[:, hkey].loc[:, vkey]) % (2 * np.pi)\n",
    "    rt.loc[:, rkey] = (np.pi + rt.loc[:, hkey].loc[:, rkey]) % (2 * np.pi)\n",
    "\n",
    "    # Fill quadrant tallies\n",
    "    hkey = [2, 1, 4, 3]\n",
    "    vkey = [4, 3, 2, 1]\n",
    "    rkey = [3, 4, 1, 2]\n",
    "\n",
    "    ht.loc[:, [f\"fluxQ{i}\" for i in hkey]] = data.loc[:, flux_cols].values\n",
    "    vt.loc[:, [f\"fluxQ{i}\" for i in vkey]] = data.loc[:, flux_cols].values\n",
    "    rt.loc[:, [f\"fluxQ{i}\" for i in rkey]] = data.loc[:, flux_cols].values\n",
    "\n",
    "    sym_data = xr.concat([data, ht, vt, rt], dim=\"index\").sortby(\"index\")\n",
    "    \n",
    "    # Normalize fluxes\n",
    "    sym_data.loc[:, flux_cols].values = Normalizer().transform(sym_data.loc[:, flux_cols].values)\n",
    "    \n",
    "    # Convert global coordinate system to local\n",
    "    loc_offsets = np.array(\n",
    "        [3.6820187359906447, 4.067668586955522, 2.2155167202240653 - np.pi, 2.6011665711889425 - np.pi, \n",
    "         0.5404260824008517, 0.9260759333657285, 5.3571093738138575 - np.pi, 5.742759224778734 - np.pi]\n",
    "    )\n",
    "\n",
    "    # Apply correct 0 point\n",
    "    sym_data.loc[:, theta_cols] = sym_data.loc[:, theta_cols] - loc_offsets + 2 * np.pi\n",
    "\n",
    "    # Reverse necessary angles\n",
    "    sym_data.loc[:, [f\"theta{i}\" for i in [3,4,5,6]]] *= -1\n",
    "\n",
    "    # Scale all to [0, 2 * np.pi]\n",
    "    sym_data.loc[:, theta_cols] = sym_data.loc[:, theta_cols] % (2 * np.pi)\n",
    "        \n",
    "    return sym_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e9375ce-4349-4565-9338-c8e6cefe17fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(combined_df, test_size=0.3)\n",
    "\n",
    "# Convert to xarray DataArray and specify the index as a coordinate\n",
    "train_data_xr = xr.DataArray(\n",
    "    train_data.values,\n",
    "    coords={\"index\": train_data.index, \"variable\": train_data.columns},\n",
    "    dims=[\"index\", \"variable\"]\n",
    ")\n",
    "test_data_xr = xr.DataArray(\n",
    "    test_data.values,\n",
    "    coords={\"index\": test_data.index, \"variable\": test_data.columns},\n",
    "    dims=[\"index\", \"variable\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "638ecb25-2331-47d6-84b6-52664a22a91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplied training shape: (2100, 12), Multiplied testing shape: (904, 12)\n"
     ]
    }
   ],
   "source": [
    "sym_train_data = mult_samples(train_data_xr)\n",
    "sym_test_data = mult_samples(test_data_xr)\n",
    "print(f\"Multiplied training shape: {sym_train_data.shape}, Multiplied testing shape: {sym_test_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4eda46-66b5-46bc-8034-b05cc46d2011",
   "metadata": {},
   "source": [
    "As seen above, we end up with data the same size as the original HTGR. Below, we are going to Min-Max the X_data and normalize the y_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3273166b-5d63-491b-872e-f8fe45b33e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max scaling data \n",
    "def scale_data(train_data, test_data, scaler):\n",
    "    train_data.values = scaler.fit_transform(\n",
    "        train_data.values.reshape(-1, train_data.shape[-1])\n",
    "    ).reshape(train_data.shape)\n",
    "    test_data.values = scaler.transform(\n",
    "        test_data.values.reshape(-1, test_data.shape[-1])\n",
    "    ).reshape(test_data.shape)\n",
    "    \n",
    "    # Return data\n",
    "    return train_data, test_data, scaler\n",
    "\n",
    "xtrain_arr, xtest_arr , _ = scale_data(sym_train_data.loc[:, theta_cols], sym_test_data.loc[:, theta_cols], MinMaxScaler())\n",
    "ytrain_arr, ytest_arr, _ = scale_data(sym_train_data.loc[:, flux_cols], sym_test_data.loc[:, flux_cols], Normalizer(norm=\"l1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbbecbde-b745-48f4-a7d7-81cc88e2373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain_arr.to_pandas()\n",
    "xtest = xtest_arr.to_pandas()\n",
    "ytrain = ytrain_arr.to_pandas()\n",
    "ytest = ytest_arr.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b1ff10-3f19-469d-8daa-8ed8a715bc1f",
   "metadata": {},
   "source": [
    "## Benchmark with H20ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5867ec22-1ead-4f68-922d-06dbb936c8d4",
   "metadata": {},
   "source": [
    "Now that all the data is preprocessed in the same fashion as the original HTGR example, it is time to use H2OML to obtain results. Below, we import the necessary libraries from H2O and initialize the H2O instance for the next tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "feeb8520-f582-48c3-9374-e106e5751e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.24\" 2024-07-16; OpenJDK Runtime Environment (build 11.0.24+8-post-Ubuntu-1ubuntu322.04); OpenJDK 64-Bit Server VM (build 11.0.24+8-post-Ubuntu-1ubuntu322.04, mixed mode, sharing)\n",
      "  Starting server from /home/schidige/anaconda3/envs/h2oML/lib/python3.8/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpqy9lzok0\n",
      "  JVM stdout: /tmp/tmpqy9lzok0/h2o_schidige_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpqy9lzok0/h2o_schidige_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.5</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 22 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_schidige_rvz83h</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>29.97 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.20 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O_cluster_uptime:         01 secs\n",
       "H2O_cluster_timezone:       America/New_York\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.5\n",
       "H2O_cluster_version_age:    1 month and 22 days\n",
       "H2O_cluster_name:           H2O_from_python_schidige_rvz83h\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    29.97 Gb\n",
       "H2O_cluster_total_cores:    32\n",
       "H2O_cluster_allowed_cores:  32\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.20 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# Step 1: Initialize H2O\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e61836d-dc0a-4728-a1fc-bf7c2da232d3",
   "metadata": {},
   "source": [
    "After that, we are going to put each of our dataset splits on the connection through H2OFrame. This lets H2O access our data and use it for training/testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b43187ae-6863-4860-add2-1d292145efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Assuming xtrain, xtest, ytrain, ytest are Pandas DataFrames\n",
    "xtrain_h2o = h2o.H2OFrame(xtrain)\n",
    "xtest_h2o = h2o.H2OFrame(xtest)\n",
    "ytrain_h2o = h2o.H2OFrame(ytrain)\n",
    "ytest_h2o = h2o.H2OFrame(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba7de8d-de63-4c04-bdb4-daaac02aa83b",
   "metadata": {},
   "source": [
    "We will then create a combined set of train and test datasets and also set the target and feature variables in lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca2947e7-0a5f-4cc1-900c-cfc91085024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features and targets for training\n",
    "train_h2o = xtrain_h2o.cbind(ytrain_h2o)\n",
    "test_h2o = xtest_h2o.cbind(ytest_h2o)\n",
    "\n",
    "# Specify the column names for the targets\n",
    "targets = ytrain.columns.tolist()  # List of target columns\n",
    "features = xtrain.columns.tolist()  # List of feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26dfe3f-1f2d-4209-b892-890258ea6bc9",
   "metadata": {},
   "source": [
    "It is now time to train our model. H2O is not natively multi-output while this problem has us predicting 4 variables simultaneously. This means we can't use H2O out of the box on this dataset. Instead we will naively extend the capacities of H2O by have it train a different model for each target outcome. Below, we do training an H2OAutoML model on each taget independently and then storing it inside a dictionary. It is also important to note that H2O natively does cross validation while training with a 5 fold split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a850ef2-9e15-40f1-bb39-61193b69f78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store models\n",
    "aml_models = {}\n",
    "\n",
    "for target in targets:\n",
    "    # Initialize AutoML\n",
    "    aml = H2OAutoML(max_models=20, seed=1234)\n",
    "\n",
    "    # Train AutoML for each target\n",
    "    aml.train(x=features, y=target, training_frame=train_h2o)\n",
    "\n",
    "    # Store the model\n",
    "    aml_models[target] = aml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb297dcf-cec6-4242-962b-518b10e1a0f7",
   "metadata": {},
   "source": [
    "After training, we can test our models below on the testing dataset we set aside earlier. Note that the $R^2$ for all the models are quite similar to the FNN's performance on HTGR, showing similar results. The same can be said about RMSE and MAE. It is also important to note that there are 4 different sets of results here for each target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38d687e9-5883-4810-8c16-5d8cc48ffecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "Evaluation for target: fluxQ1\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 4.008380111192609e-07\n",
      "RMSE: 0.0006331176913649317\n",
      "MAE: 0.0005025689597728681\n",
      "RMSLE: 0.0005058321307694414\n",
      "Mean Residual Deviance: 4.008380111192609e-07\n",
      "R² on test set: 0.9776496656942096\n",
      "--------------------------------------------------\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "Evaluation for target: fluxQ2\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 3.8885122709052564e-07\n",
      "RMSE: 0.0006235793671141835\n",
      "MAE: 0.000492043480224217\n",
      "RMSLE: 0.0004982041393286098\n",
      "Mean Residual Deviance: 3.8885122709052564e-07\n",
      "R² on test set: 0.9783180370134837\n",
      "--------------------------------------------------\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "Evaluation for target: fluxQ3\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 4.0225058972030825e-07\n",
      "RMSE: 0.0006342322837260086\n",
      "MAE: 0.0005049802613484237\n",
      "RMSLE: 0.0005068485553018549\n",
      "Mean Residual Deviance: 4.0225058972030825e-07\n",
      "R² on test set: 0.977570901697126\n",
      "--------------------------------------------------\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "Evaluation for target: fluxQ4\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 4.011371711788862e-07\n",
      "RMSE: 0.000633353906736894\n",
      "MAE: 0.0004977111311085677\n",
      "RMSLE: 0.0005061076449568598\n",
      "Mean Residual Deviance: 4.011371711788862e-07\n",
      "R² on test set: 0.9776329848227056\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models for each target\n",
    "for target in targets:\n",
    "    # Make predictions\n",
    "    predictions = aml_models[target].leader.predict(test_h2o)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    performance = aml_models[target].leader.model_performance(test_h2o)\n",
    "    print(f\"Evaluation for target: {target}\")\n",
    "    print(performance)\n",
    "    print(f\"R² on test set: {performance.r2()}\")\n",
    "    print('-' * 50)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd08c0b-d543-451a-84a0-1932bf71ef47",
   "metadata": {},
   "source": [
    "All that is left now is to print out the model parameters for all the models trained in a leaderboard style (best to worst). We can see that H2O models that are used were mainly Gradient Boosting and XGBoost models. Again, we are printing the leaderboard for each target variable. However, we can see that each leaderboard gives pretty consistant results across all the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "534984a9-cae3-43fa-8823-cf4a1c32ba64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Leaderboard for target: fluxQ1\n",
      "model_id                                           rmse          mse          mae        rmsle    mean_residual_deviance\n",
      "GBM_1_AutoML_1_20241023_32520               0.000685361  4.69719e-07  0.000542796  0.000547656               4.69719e-07\n",
      "GBM_grid_1_AutoML_1_20241023_32520_model_2  0.000766287  5.87195e-07  0.00060316   0.000612268               5.87195e-07\n",
      "GBM_2_AutoML_1_20241023_32520               0.000945019  8.93061e-07  0.000742318  0.000755141               8.93061e-07\n",
      "GBM_3_AutoML_1_20241023_32520               0.000973695  9.48082e-07  0.000769139  0.000778094               9.48082e-07\n",
      "XGBoost_3_AutoML_1_20241023_32520           0.000985956  9.72109e-07  0.000778139  0.000788122               9.72109e-07\n",
      "GBM_5_AutoML_1_20241023_32520               0.000996767  9.93544e-07  0.000779383  0.000796456               9.93544e-07\n",
      "GBM_4_AutoML_1_20241023_32520               0.00102334   1.04723e-06  0.000806216  0.000817664               1.04723e-06\n",
      "XGBoost_1_AutoML_1_20241023_32520           0.00106348   1.13098e-06  0.000832568  0.000849964               1.13098e-06\n",
      "GBM_grid_1_AutoML_1_20241023_32520_model_1  0.00108547   1.17825e-06  0.000862658  0.000867518               1.17825e-06\n",
      "XGBoost_2_AutoML_1_20241023_32520           0.00117195   1.37348e-06  0.000923484  0.000936506               1.37348e-06\n",
      "[22 rows x 6 columns]\n",
      "\n",
      "Best model for fluxQ1: Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
      "Model Key: GBM_1_AutoML_1_20241023_32520\n",
      "\n",
      "\n",
      "Model Summary: \n",
      "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
      "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
      "    214                214                         47211                  5            12           6.64019       11            15            12.9019\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 1.6331278682565502e-07\n",
      "RMSE: 0.00040411976792240073\n",
      "MAE: 0.0003163858609540122\n",
      "RMSLE: 0.00032308420724847767\n",
      "Mean Residual Deviance: 1.6331278682565502e-07\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 4.697191557378037e-07\n",
      "RMSE: 0.0006853606027032804\n",
      "MAE: 0.0005427964198011339\n",
      "RMSLE: 0.0005476564684272209\n",
      "Mean Residual Deviance: 4.697191557378037e-07\n",
      "\n",
      "Cross-Validation Metrics Summary: \n",
      "                        mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
      "----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
      "aic                     nan          0            nan           nan           nan           nan           nan\n",
      "loglikelihood           nan          0            nan           nan           nan           nan           nan\n",
      "mae                     0.000542796  1.31243e-05  0.000538211   0.000530016   0.000560481   0.00055243    0.000532844\n",
      "mean_residual_deviance  4.69719e-07  2.33523e-08  4.54558e-07   4.60519e-07   4.87936e-07   5.00324e-07   4.45259e-07\n",
      "mse                     4.69719e-07  2.33523e-08  4.54558e-07   4.60519e-07   4.87936e-07   5.00324e-07   4.45259e-07\n",
      "r2                      0.973282     0.00149219   0.973758      0.974979      0.971066      0.972635      0.973969\n",
      "residual_deviance       4.69719e-07  2.33523e-08  4.54558e-07   4.60519e-07   4.87936e-07   5.00324e-07   4.45259e-07\n",
      "rmse                    0.000685192  1.69773e-05  0.000674209   0.000678615   0.000698524   0.000707336   0.000667277\n",
      "rmsle                   0.00054752   1.36616e-05  0.000538584   0.000542178   0.000558484   0.000565184   0.00053317\n",
      "\n",
      "Scoring History: \n",
      "     timestamp            duration    number_of_trees    training_rmse           training_mae            training_deviance\n",
      "---  -------------------  ----------  -----------------  ----------------------  ----------------------  ----------------------\n",
      "     2024-10-23 03:25:24  0.865 sec   0.0                0.004201010689797002    0.0033778119158177195   1.764849081578869e-05\n",
      "     2024-10-23 03:25:24  0.889 sec   5.0                0.0034190857716209617   0.0027252461512883505   1.1690147513700905e-05\n",
      "     2024-10-23 03:25:24  0.911 sec   10.0               0.002810227376203113    0.002228595025482632    7.897377905961435e-06\n",
      "     2024-10-23 03:25:24  0.929 sec   15.0               0.0023530311674819487   0.0018721228412219456   5.536755675141463e-06\n",
      "     2024-10-23 03:25:24  0.955 sec   20.0               0.00203453340498974     0.0016157419340951103   4.139326176019145e-06\n",
      "     2024-10-23 03:25:24  0.980 sec   25.0               0.0017813600224910193   0.0014127596432254427   3.173243529729205e-06\n",
      "     2024-10-23 03:25:24  0.999 sec   30.0               0.0015817458323410948   0.00125214146006675     2.5019198781284225e-06\n",
      "     2024-10-23 03:25:24  1.010 sec   35.0               0.001407358676304971    0.0011104385696706317   1.98065844377088e-06\n",
      "     2024-10-23 03:25:24  1.017 sec   40.0               0.0012673626148236852   0.000994884031159537    1.6062079974527286e-06\n",
      "     2024-10-23 03:25:24  1.025 sec   45.0               0.0011565484099844263   0.0009059004130817595   1.3376042246375045e-06\n",
      "---  ---                  ---         ---                ---                     ---                     ---\n",
      "     2024-10-23 03:25:24  1.166 sec   170.0              0.00043863169837880735  0.00034314684924625216  1.9239776682267702e-07\n",
      "     2024-10-23 03:25:24  1.172 sec   175.0              0.00043411767239254917  0.0003398880007721129   1.8845815348352463e-07\n",
      "     2024-10-23 03:25:24  1.178 sec   180.0              0.0004298357716996795   0.0003370365216618493   1.8475879063265902e-07\n",
      "     2024-10-23 03:25:24  1.183 sec   185.0              0.0004259582440229696   0.00033383660373233616  1.8144042565113172e-07\n",
      "     2024-10-23 03:25:24  1.189 sec   190.0              0.0004221228339103973   0.00033074041917210533  1.7818768690854488e-07\n",
      "     2024-10-23 03:25:24  1.194 sec   195.0              0.00041788367495367907  0.0003273369584764753   1.746267657927921e-07\n",
      "     2024-10-23 03:25:24  1.200 sec   200.0              0.0004136387071495793   0.00032392779276484536  1.7109698005237546e-07\n",
      "     2024-10-23 03:25:24  1.206 sec   205.0              0.00041072468443775024  0.00032179740213212515  1.686947664064895e-07\n",
      "     2024-10-23 03:25:24  1.211 sec   210.0              0.00040694037215320046  0.0003185727908497765   1.6560046648818527e-07\n",
      "     2024-10-23 03:25:24  1.216 sec   214.0              0.00040411976792240073  0.0003163858609540122   1.6331278682565502e-07\n",
      "[44 rows x 7 columns]\n",
      "\n",
      "\n",
      "Variable Importances: \n",
      "variable    relative_importance    scaled_importance    percentage\n",
      "----------  ---------------------  -------------------  ------------\n",
      "theta1      0.0627416              1                    0.379852\n",
      "theta2      0.0548633              0.874434             0.332155\n",
      "theta5      0.017366               0.276786             0.105138\n",
      "theta6      0.014772               0.235441             0.0894328\n",
      "theta7      0.00608472             0.0969806            0.0368383\n",
      "theta4      0.00589191             0.0939076            0.035671\n",
      "theta8      0.00173475             0.0276491            0.0105026\n",
      "theta3      0.0017196              0.0274077            0.0104108\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Leaderboard for target: fluxQ2\n",
      "model_id                                           rmse          mse          mae        rmsle    mean_residual_deviance\n",
      "GBM_1_AutoML_2_20241023_32739               0.000666645  4.44415e-07  0.000528096  0.000532684               4.44415e-07\n",
      "GBM_grid_1_AutoML_2_20241023_32739_model_2  0.00075398   5.68486e-07  0.000591372  0.000602509               5.68486e-07\n",
      "GBM_2_AutoML_2_20241023_32739               0.000944374  8.91842e-07  0.00073735   0.000754506               8.91842e-07\n",
      "GBM_3_AutoML_2_20241023_32739               0.000957021  9.1589e-07   0.000756335  0.000764697               9.1589e-07\n",
      "GBM_5_AutoML_2_20241023_32739               0.0009706    9.42065e-07  0.00075692   0.000775477               9.42065e-07\n",
      "XGBoost_3_AutoML_2_20241023_32739           0.000984195  9.68639e-07  0.00078467   0.000786657               9.68639e-07\n",
      "GBM_4_AutoML_2_20241023_32739               0.00100781   1.01569e-06  0.000798048  0.000805267               1.01569e-06\n",
      "XGBoost_1_AutoML_2_20241023_32739           0.00102376   1.04809e-06  0.000808626  0.000818355               1.04809e-06\n",
      "GBM_grid_1_AutoML_2_20241023_32739_model_1  0.00111303   1.23885e-06  0.00088144   0.000889503               1.23885e-06\n",
      "XGBoost_2_AutoML_2_20241023_32739           0.00116277   1.35202e-06  0.000921097  0.000929546               1.35202e-06\n",
      "[22 rows x 6 columns]\n",
      "\n",
      "Best model for fluxQ2: Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
      "Model Key: GBM_1_AutoML_2_20241023_32739\n",
      "\n",
      "\n",
      "Model Summary: \n",
      "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
      "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
      "    232                232                         51225                  5            10           6.73707       11            15            12.9009\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 1.5099336540128997e-07\n",
      "RMSE: 0.00038857864763943215\n",
      "MAE: 0.00030885128038270134\n",
      "RMSLE: 0.0003106507832008333\n",
      "Mean Residual Deviance: 1.5099336540128997e-07\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 4.4441549201724677e-07\n",
      "RMSE: 0.0006666449519926231\n",
      "MAE: 0.0005280959649242026\n",
      "RMSLE: 0.0005326838418565784\n",
      "Mean Residual Deviance: 4.4441549201724677e-07\n",
      "\n",
      "Cross-Validation Metrics Summary: \n",
      "                        mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
      "----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
      "aic                     nan          0            nan           nan           nan           nan           nan\n",
      "loglikelihood           nan          0            nan           nan           nan           nan           nan\n",
      "mae                     0.000528096  2.70101e-05  0.000509151   0.000553827   0.000490432   0.000544519   0.00054255\n",
      "mean_residual_deviance  4.44415e-07  3.30293e-08  4.37549e-07   4.86273e-07   3.95044e-07   4.48174e-07   4.55039e-07\n",
      "mse                     4.44415e-07  3.30293e-08  4.37549e-07   4.86273e-07   3.95044e-07   4.48174e-07   4.55039e-07\n",
      "r2                      0.974713     0.00278013   0.976243      0.971341      0.978574      0.973339      0.974066\n",
      "residual_deviance       4.44415e-07  3.30293e-08  4.37549e-07   4.86273e-07   3.95044e-07   4.48174e-07   4.55039e-07\n",
      "rmse                    0.000666271  2.49577e-05  0.000661474   0.000697333   0.000628525   0.000669458   0.000674566\n",
      "rmsle                   0.000532382  2.00328e-05  0.000528159   0.000557246   0.000502127   0.000535247   0.000539133\n",
      "\n",
      "Scoring History: \n",
      "     timestamp            duration    number_of_trees    training_rmse           training_mae            training_deviance\n",
      "---  -------------------  ----------  -----------------  ----------------------  ----------------------  ----------------------\n",
      "     2024-10-23 03:27:40  0.420 sec   0.0                0.0042010106897970015   0.0033778119158177165   1.7648490815788678e-05\n",
      "     2024-10-23 03:27:40  0.426 sec   5.0                0.0034189064007153075   0.002755580430939084    1.1688920976852099e-05\n",
      "     2024-10-23 03:27:40  0.431 sec   10.0               0.002753995370508964    0.00219750185807546     7.584490500784807e-06\n",
      "     2024-10-23 03:27:40  0.437 sec   15.0               0.0023605017980835455   0.0018795494664283026   5.571968738755651e-06\n",
      "     2024-10-23 03:27:40  0.442 sec   20.0               0.002005577924567542    0.001596005984715053    4.02234281151265e-06\n",
      "     2024-10-23 03:27:40  0.447 sec   25.0               0.0017670810062046143   0.001399007070632208    3.122575282489112e-06\n",
      "     2024-10-23 03:27:40  0.452 sec   30.0               0.0015582377414062273   0.0012330717416036696   2.4281048587427803e-06\n",
      "     2024-10-23 03:27:40  0.458 sec   35.0               0.0013934382528751693   0.0010996492136092413   1.941670164575804e-06\n",
      "     2024-10-23 03:27:40  0.463 sec   40.0               0.0012580393440821257   0.0009919860462347667   1.582662991258585e-06\n",
      "     2024-10-23 03:27:40  0.468 sec   45.0               0.0011436701653217791   0.0008994359984284356   1.3079814470471458e-06\n",
      "---  ---                  ---         ---                ---                     ---                     ---\n",
      "     2024-10-23 03:27:40  0.621 sec   190.0              0.00041807011294505157  0.0003314097438539778   1.7478261933788817e-07\n",
      "     2024-10-23 03:27:40  0.626 sec   195.0              0.0004143686431392978   0.00032852509901637125  1.7170137241710275e-07\n",
      "     2024-10-23 03:27:40  0.632 sec   200.0              0.00041075333746739683  0.00032629044283004035  1.6871830424060517e-07\n",
      "     2024-10-23 03:27:40  0.637 sec   205.0              0.0004072874678658136   0.0003237103848230271   1.6588308148054612e-07\n",
      "     2024-10-23 03:27:40  0.642 sec   210.0              0.00040341464243058307  0.0003207209777264368   1.6274337372739517e-07\n",
      "     2024-10-23 03:27:40  0.648 sec   215.0              0.0003996149487542951   0.00031803920155479797  1.596921072678979e-07\n",
      "     2024-10-23 03:27:40  0.654 sec   220.0              0.00039626481175479046  0.0003153943234965915   1.570258010350595e-07\n",
      "     2024-10-23 03:27:40  0.659 sec   225.0              0.00039280958057331304  0.0003124307450794038   1.542993665901821e-07\n",
      "     2024-10-23 03:27:40  0.665 sec   230.0              0.0003897637814427752   0.00030984618834086825  1.519158053245714e-07\n",
      "     2024-10-23 03:27:40  0.668 sec   232.0              0.00038857864763943215  0.00030885128038270134  1.5099336540128997e-07\n",
      "[48 rows x 7 columns]\n",
      "\n",
      "\n",
      "Variable Importances: \n",
      "variable    relative_importance    scaled_importance    percentage\n",
      "----------  ---------------------  -------------------  ------------\n",
      "theta4      0.0632612              1                    0.381511\n",
      "theta3      0.0543378              0.858944             0.327696\n",
      "theta8      0.0177624              0.28078              0.10712\n",
      "theta7      0.0147892              0.23378              0.0891895\n",
      "theta6      0.006291               0.0994448            0.0379393\n",
      "theta1      0.00605141             0.0956576            0.0364944\n",
      "theta5      0.00167385             0.0264593            0.0100945\n",
      "theta2      0.00165073             0.0260939            0.00995511\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Leaderboard for target: fluxQ3\n",
      "model_id                                           rmse          mse          mae        rmsle    mean_residual_deviance\n",
      "GBM_1_AutoML_3_20241023_32951               0.00066506   4.42305e-07  0.000522491  0.000531438               4.42305e-07\n",
      "GBM_grid_1_AutoML_3_20241023_32951_model_2  0.000759034  5.76133e-07  0.000591843  0.000606594               5.76133e-07\n",
      "GBM_2_AutoML_3_20241023_32951               0.000946011  8.94937e-07  0.000741802  0.000755897               8.94937e-07\n",
      "GBM_5_AutoML_3_20241023_32951               0.000969073  9.39103e-07  0.000768166  0.000774454               9.39103e-07\n",
      "GBM_3_AutoML_3_20241023_32951               0.000979783  9.59974e-07  0.000764376  0.000783008               9.59974e-07\n",
      "GBM_4_AutoML_3_20241023_32951               0.000994735  9.89497e-07  0.000786269  0.000794846               9.89497e-07\n",
      "XGBoost_3_AutoML_3_20241023_32951           0.00100103   1.00206e-06  0.00079418   0.000800109               1.00206e-06\n",
      "XGBoost_1_AutoML_3_20241023_32951           0.00106398   1.13205e-06  0.00084634   0.000850548               1.13205e-06\n",
      "GBM_grid_1_AutoML_3_20241023_32951_model_1  0.00111174   1.23596e-06  0.000882908  0.000888529               1.23596e-06\n",
      "XGBoost_2_AutoML_3_20241023_32951           0.0011786    1.38911e-06  0.000923643  0.000942039               1.38911e-06\n",
      "[22 rows x 6 columns]\n",
      "\n",
      "Best model for fluxQ3: Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
      "Model Key: GBM_1_AutoML_3_20241023_32951\n",
      "\n",
      "\n",
      "Model Summary: \n",
      "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
      "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
      "    234                234                         51841                  5            10           6.73077       11            15            12.9615\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 1.493456961269383e-07\n",
      "RMSE: 0.0003864527087845786\n",
      "MAE: 0.00030561133509590514\n",
      "RMSLE: 0.00030899687989079105\n",
      "Mean Residual Deviance: 1.493456961269383e-07\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 4.42304993025337e-07\n",
      "RMSE: 0.0006650601424122009\n",
      "MAE: 0.0005224908919147636\n",
      "RMSLE: 0.0005314384086717635\n",
      "Mean Residual Deviance: 4.42304993025337e-07\n",
      "\n",
      "Cross-Validation Metrics Summary: \n",
      "                        mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
      "----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
      "aic                     nan          0            nan           nan           nan           nan           nan\n",
      "loglikelihood           nan          0            nan           nan           nan           nan           nan\n",
      "mae                     0.000522491  2.18906e-05  0.000548144   0.00054168    0.000505729   0.000498076   0.000518825\n",
      "mean_residual_deviance  4.42305e-07  4.03101e-08  4.86119e-07   4.83604e-07   4.17081e-07   3.9745e-07    4.27271e-07\n",
      "mse                     4.42305e-07  4.03101e-08  4.86119e-07   4.83604e-07   4.17081e-07   3.9745e-07    4.27271e-07\n",
      "r2                      0.974731     0.00362993   0.96933       0.973208      0.977859      0.978083      0.975175\n",
      "residual_deviance       4.42305e-07  4.03101e-08  4.86119e-07   4.83604e-07   4.17081e-07   3.9745e-07    4.27271e-07\n",
      "rmse                    0.000664511  3.02221e-05  0.000697223   0.000695417   0.000645818   0.000630436   0.000653659\n",
      "rmsle                   0.000530996  2.42349e-05  0.000557269   0.000555726   0.000515868   0.000503701   0.000522417\n",
      "\n",
      "Scoring History: \n",
      "     timestamp            duration    number_of_trees    training_rmse           training_mae            training_deviance\n",
      "---  -------------------  ----------  -----------------  ----------------------  ----------------------  ----------------------\n",
      "     2024-10-23 03:29:52  0.414 sec   0.0                0.004201010689797002    0.0033778119158177186   1.764849081578869e-05\n",
      "     2024-10-23 03:29:52  0.420 sec   5.0                0.0033117992293671544   0.0026528380314509072   1.0968014135636877e-05\n",
      "     2024-10-23 03:29:52  0.425 sec   10.0               0.0027753717087465675   0.002217293516511009    7.702688121710842e-06\n",
      "     2024-10-23 03:29:52  0.430 sec   15.0               0.002348862808689713    0.0018691390256086985   5.5171564940457265e-06\n",
      "     2024-10-23 03:29:52  0.435 sec   20.0               0.002043271002061544    0.0016216694386232467   4.174956387865586e-06\n",
      "     2024-10-23 03:29:52  0.440 sec   25.0               0.0017947391354647246   0.001424937972000667    3.2210885643686673e-06\n",
      "     2024-10-23 03:29:52  0.445 sec   30.0               0.00159472235896177     0.0012614684516475314   2.5431394021725925e-06\n",
      "     2024-10-23 03:29:52  0.450 sec   35.0               0.001427722266175823    0.0011272070166610537   2.0383908693342274e-06\n",
      "     2024-10-23 03:29:52  0.455 sec   40.0               0.001294380138889908    0.0010192357500394184   1.6754199439526574e-06\n",
      "     2024-10-23 03:29:52  0.460 sec   45.0               0.001172273388192027    0.0009192545144330888   1.3742248966632152e-06\n",
      "---  ---                  ---         ---                ---                     ---                     ---\n",
      "     2024-10-23 03:29:52  0.618 sec   190.0              0.0004187731351611232   0.0003299681984242939   1.7537093873267633e-07\n",
      "     2024-10-23 03:29:52  0.623 sec   195.0              0.00041523292467442733  0.00032747069994608564  1.7241838173367864e-07\n",
      "     2024-10-23 03:29:52  0.629 sec   200.0              0.00041115355874123615  0.0003241806087039766   1.6904724886558312e-07\n",
      "     2024-10-23 03:29:52  0.635 sec   205.0              0.00040638562548642393  0.00032032632402011327  1.65149276601992e-07\n",
      "     2024-10-23 03:29:52  0.640 sec   210.0              0.0004025827204136496   0.0003177240916660854   1.6207284677565477e-07\n",
      "     2024-10-23 03:29:52  0.646 sec   215.0              0.00039956708282097055  0.00031522626678148904  1.5965385367406035e-07\n",
      "     2024-10-23 03:29:52  0.652 sec   220.0              0.0003957602695231215   0.0003126263121763865   1.5662619093301377e-07\n",
      "     2024-10-23 03:29:53  0.657 sec   225.0              0.0003921905502061792   0.0003098773530551365   1.5381342767102558e-07\n",
      "     2024-10-23 03:29:53  0.663 sec   230.0              0.00038911633471645643  0.00030744881857009163  1.5141152194316935e-07\n",
      "     2024-10-23 03:29:53  0.667 sec   234.0              0.0003864527087845786   0.00030561133509590514  1.493456961269383e-07\n",
      "[48 rows x 7 columns]\n",
      "\n",
      "\n",
      "Variable Importances: \n",
      "variable    relative_importance    scaled_importance    percentage\n",
      "----------  ---------------------  -------------------  ------------\n",
      "theta5      0.0627204              1                    0.379668\n",
      "theta6      0.0547693              0.873229             0.331537\n",
      "theta1      0.0169435              0.270143             0.102565\n",
      "theta2      0.0149594              0.238509             0.0905544\n",
      "theta8      0.00610147             0.0972804            0.0369343\n",
      "theta3      0.00607011             0.0967804            0.0367444\n",
      "theta4      0.00191                0.0304526            0.0115619\n",
      "theta7      0.00172383             0.0274844            0.0104349\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Leaderboard for target: fluxQ4\n",
      "model_id                                           rmse          mse          mae        rmsle    mean_residual_deviance\n",
      "GBM_1_AutoML_4_20241023_33207               0.000661857  4.38054e-07  0.000523309  0.000528991               4.38054e-07\n",
      "GBM_grid_1_AutoML_4_20241023_33207_model_2  0.000759653  5.77073e-07  0.000600732  0.000606976               5.77073e-07\n",
      "GBM_2_AutoML_4_20241023_33207               0.000930048  8.6499e-07   0.000737675  0.000743301               8.6499e-07\n",
      "GBM_5_AutoML_4_20241023_33207               0.000965944  9.33048e-07  0.000764493  0.000771864               9.33048e-07\n",
      "GBM_3_AutoML_4_20241023_33207               0.000976795  9.54128e-07  0.000777304  0.000780649               9.54128e-07\n",
      "GBM_4_AutoML_4_20241023_33207               0.00100016   1.00032e-06  0.000801409  0.000799579               1.00032e-06\n",
      "XGBoost_3_AutoML_4_20241023_33207           0.00102218   1.04484e-06  0.000811577  0.000817006               1.04484e-06\n",
      "GBM_grid_1_AutoML_4_20241023_33207_model_1  0.00109561   1.20036e-06  0.000869224  0.000875739               1.20036e-06\n",
      "XGBoost_1_AutoML_4_20241023_33207           0.00112215   1.25923e-06  0.000884476  0.000897058               1.25923e-06\n",
      "XGBoost_2_AutoML_4_20241023_33207           0.00113872   1.29667e-06  0.000894447  0.000910263               1.29667e-06\n",
      "[22 rows x 6 columns]\n",
      "\n",
      "Best model for fluxQ4: Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
      "Model Key: GBM_1_AutoML_4_20241023_33207\n",
      "\n",
      "\n",
      "Model Summary: \n",
      "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
      "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
      "    242                242                         53527                  5            10           6.7562        11            15            12.9339\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 1.4928759705323814e-07\n",
      "RMSE: 0.0003863775317655494\n",
      "MAE: 0.00030924480585824875\n",
      "RMSLE: 0.00030897086341989167\n",
      "Mean Residual Deviance: 1.4928759705323814e-07\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 4.3805439122159745e-07\n",
      "RMSE: 0.0006618567754594625\n",
      "MAE: 0.000523309145664202\n",
      "RMSLE: 0.0005289910747630794\n",
      "Mean Residual Deviance: 4.3805439122159745e-07\n",
      "\n",
      "Cross-Validation Metrics Summary: \n",
      "                        mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
      "----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
      "aic                     nan          0            nan           nan           nan           nan           nan\n",
      "loglikelihood           nan          0            nan           nan           nan           nan           nan\n",
      "mae                     0.000523309  3.30866e-05  0.00050479    0.000551298   0.0005243     0.000558059   0.000478099\n",
      "mean_residual_deviance  4.38054e-07  5.10323e-08  4.06417e-07   4.80216e-07   4.40655e-07   4.92915e-07   3.70068e-07\n",
      "mse                     4.38054e-07  5.10323e-08  4.06417e-07   4.80216e-07   4.40655e-07   4.92915e-07   3.70068e-07\n",
      "r2                      0.975189     0.00210843   0.975949      0.973051      0.976248      0.972955      0.977742\n",
      "residual_deviance       4.38054e-07  5.10323e-08  4.06417e-07   4.80216e-07   4.40655e-07   4.92915e-07   3.70068e-07\n",
      "rmse                    0.000660943  3.88706e-05  0.000637509   0.000692977   0.000663819   0.000702079   0.000608332\n",
      "rmsle                   0.000528265  3.09804e-05  0.000509871   0.000553647   0.000530504   0.000561128   0.000486175\n",
      "\n",
      "Scoring History: \n",
      "     timestamp            duration    number_of_trees    training_rmse           training_mae            training_deviance\n",
      "---  -------------------  ----------  -----------------  ----------------------  ----------------------  ----------------------\n",
      "     2024-10-23 03:32:08  0.437 sec   0.0                0.004201010689797002    0.0033778119158177195   1.764849081578869e-05\n",
      "     2024-10-23 03:32:08  0.443 sec   5.0                0.0032377035514388115   0.0026033101834001997   1.0482724286999494e-05\n",
      "     2024-10-23 03:32:08  0.448 sec   10.0               0.0027126304259239955   0.0021702216991356443   7.358363827648598e-06\n",
      "     2024-10-23 03:32:08  0.454 sec   15.0               0.0023150232359903885   0.0018431942022982097   5.35933258317541e-06\n",
      "     2024-10-23 03:32:08  0.459 sec   20.0               0.0020154108985627845   0.0016047244057768868   4.061881090045651e-06\n",
      "     2024-10-23 03:32:08  0.464 sec   25.0               0.001783390970047642    0.0014166246851285299   3.180483352047469e-06\n",
      "     2024-10-23 03:32:08  0.469 sec   30.0               0.001590353971752259    0.0012585039862564632   2.5292257554681854e-06\n",
      "     2024-10-23 03:32:08  0.474 sec   35.0               0.0014283456511595693   0.0011312026707899002   2.040171299186454e-06\n",
      "     2024-10-23 03:32:08  0.480 sec   40.0               0.0012980488231495303   0.001027571154492242    1.6849307472798806e-06\n",
      "     2024-10-23 03:32:08  0.485 sec   45.0               0.00117923036729206     0.0009335457072371528   1.3905842591437663e-06\n",
      "---  ---                  ---         ---                ---                     ---                     ---\n",
      "     2024-10-23 03:32:08  0.649 sec   200.0              0.00041755541477453016  0.00033326026229631335  1.7435252440752994e-07\n",
      "     2024-10-23 03:32:08  0.655 sec   205.0              0.0004138400513103363   0.00033017737524850026  1.712635880685418e-07\n",
      "     2024-10-23 03:32:08  0.661 sec   210.0              0.0004101445372666396   0.0003273545134635199   1.6821854144966592e-07\n",
      "     2024-10-23 03:32:08  0.666 sec   215.0              0.0004062373085734939   0.00032462202367328463  1.6502875087703608e-07\n",
      "     2024-10-23 03:32:08  0.671 sec   220.0              0.0004024412510854033   0.00032183952984355746  1.6195896057518462e-07\n",
      "     2024-10-23 03:32:08  0.677 sec   225.0              0.00039844592860989865  0.0003188148992402213   1.5875915802580445e-07\n",
      "     2024-10-23 03:32:08  0.683 sec   230.0              0.00039493119718597957  0.00031597646928968885  1.5597065051075106e-07\n",
      "     2024-10-23 03:32:08  0.688 sec   235.0              0.00039116385521705167  0.00031291855233056207  1.5300916162826656e-07\n",
      "     2024-10-23 03:32:08  0.694 sec   240.0              0.0003876882931526777   0.0003102123382545653   1.5030221264763657e-07\n",
      "     2024-10-23 03:32:08  0.696 sec   242.0              0.0003863775317655494   0.00030924480585824875  1.4928759705323814e-07\n",
      "[50 rows x 7 columns]\n",
      "\n",
      "\n",
      "Variable Importances: \n",
      "variable    relative_importance    scaled_importance    percentage\n",
      "----------  ---------------------  -------------------  ------------\n",
      "theta8      0.0633288              1                    0.385543\n",
      "theta7      0.054432               0.859515             0.33138\n",
      "theta4      0.0169941              0.268348             0.10346\n",
      "theta3      0.014081               0.222347             0.0857244\n",
      "theta2      0.00624284             0.0985783            0.0380062\n",
      "theta5      0.0057615              0.0909776            0.0350758\n",
      "theta1      0.00179929             0.0284118            0.010954\n",
      "theta6      0.0016191              0.0255666            0.00985701\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for target, aml in aml_models.items():\n",
    "    print(f\"\\nLeaderboard for target: {target}\")\n",
    "    print(aml.leaderboard)\n",
    "    print(f\"Best model for {target}: {aml.leader}\")\n",
    "    print('-' * 100)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c9aed6-712f-4860-892a-21613617f8c7",
   "metadata": {},
   "source": [
    "All that is left is to shutdown the cluster since we initalized it earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18982bb-2f86-4c23-87d0-6ee13b7ec40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
